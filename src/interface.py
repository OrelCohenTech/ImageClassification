import torch
import cv2
import numpy as np
from PIL import Image
from torchvision import transforms
import os

# ×™×™×‘×•× ×”××•×“×œ ×•×”×¤×•× ×§×¦×™×” ×©×œ ×”×ª×“×¨×™× ×©×‘× ×™× ×•
from model import FakeDetectDualNet
from datast import DualStreamDataset 

# --- ×”×’×“×¨×•×ª ---
MODEL_PATH = "fake_image_classifier.pth" # ×•×“××• ×©×”×§×•×‘×¥ ×”×–×” ×§×™×™× ×‘×ª×™×§×™×™×” ×”×¨××©×™×ª
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ××™×¤×•×™ ×”××—×œ×§×•×ª (×—×™×™×‘ ×œ×”×™×•×ª ×–×”×” ×œ××” ×©×”×’×“×¨× ×• ×‘-Dataset)
CLASSES = {0: 'REAL (Authentic)', 1: '2D (Artificial)', 2: '3D (Artificial)'}

def load_trained_model():
    print(f"Loading model from {MODEL_PATH}...")
    model = FakeDetectDualNet(num_classes=3)
    # ×˜×¢×™× ×ª ×”××©×§×•×œ×•×ª (map_location=DEVICE ×—×©×•×‘ ×× ×××× ×™× ×‘-GPU ×•×‘×•×“×§×™× ×‘-CPU)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True))
    model.to(DEVICE)
    model.eval() # ××¢×‘×¨ ×œ××¦×‘ ×—×™×–×•×™ (××›×‘×” Dropout ×•×›×•')
    return model

def prepare_image(image_path):
    """ ×”×›× ×ª ×”×ª××•× ×” ×‘×“×™×•×§ ×›××• ×‘××™××•×Ÿ (Resize + FFT) """
    # 1. ×˜×¨× ×¡×¤×•×¨××¦×™×•×ª ×‘×¡×™×¡×™×•×ª
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])
    
    # 2. ×˜×¢×™× ×ª RGB
    try:
        rgb_img = Image.open(image_path).convert('RGB')
    except Exception as e:
        print(f"Error opening image: {e}")
        return None, None

    # 3. ×™×¦×™×¨×ª FFT (××©×ª××©×™× ×‘×œ×•×’×™×§×” ×-Dataset ××‘×œ ×‘××•×¤×Ÿ ×™×“× ×™ ×›××Ÿ ×œ×¤×©×˜×•×ª)
    # × ×©×ª××© ×‘×¤×•× ×§×¦×™×™×ª ×¢×–×¨ ×§×˜× ×” ×›×“×™ ×œ× ×œ×™×¦×•×¨ ××•×‘×™×™×§×˜ Dataset ×©×œ×
    freq_img_pil = create_fft_single(image_path)

    # ×”×—×œ×ª ×”×˜×¨× ×¡×¤×•×¨××¦×™×•×ª ×•×”×•×¡×¤×ª ××™××“ Batch (×-[3, 224, 224] ×œ-[1, 3, 224, 224])
    rgb_tensor = transform(rgb_img).unsqueeze(0).to(DEVICE)
    freq_tensor = transform(freq_img_pil).unsqueeze(0).to(DEVICE)
    
    return rgb_tensor, freq_tensor

def create_fft_single(img_path):
    """ ××•×ª×” ×œ×•×’×™×§×” ×‘×“×™×•×§ ×›××• ×‘-dataset.py """
    img = cv2.imread(img_path, 0)
    if img is None: return Image.new('RGB', (224, 224))
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-9)
    magnitude_spectrum = cv2.normalize(magnitude_spectrum, None, 0, 255, cv2.NORM_MINMAX)
    magnitude_spectrum = np.uint8(magnitude_spectrum)
    magnitude_spectrum = cv2.cvtColor(magnitude_spectrum, cv2.COLOR_GRAY2RGB)
    return Image.fromarray(magnitude_spectrum)

def predict(image_path):
    # ×˜×¢×™× ×ª ××•×“×œ
    model = load_trained_model()
    
    # ×”×›× ×ª ×ª××•× ×”
    rgb_input, freq_input = prepare_image(image_path)
    if rgb_input is None: return

    print(f"\nğŸ” Analyzing image: {image_path}")
    
    with torch.no_grad():
        # ×”×¨×¦×ª ×”××•×“×œ
        outputs = model(rgb_input, freq_input)
        
        # ×—×™×©×•×‘ ×”×¡×ª×‘×¨×•×™×•×ª (Softmax)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        
        # ×§×‘×œ×ª ×”×”×—×œ×˜×” ×”×¡×•×¤×™×ª
        score, predicted_idx = torch.max(probabilities, 1)
        predicted_class = CLASSES[predicted_idx.item()]
        confidence = score.item() * 100

    print("-" * 30)
    print(f"ğŸ¤– Result: {predicted_class}")
    print(f"ğŸ“Š Confidence: {confidence:.2f}%")
    
    # ×”×“×¤×¡×ª ×›×œ ×”×”×¡×ª×‘×¨×•×™×•×ª
    print("\nDetailed Probabilities:")
    for i, class_name in CLASSES.items():
        prob = probabilities[0][i].item() * 100
        print(f"  {class_name}: {prob:.2f}%")
    print("-" * 30)

if __name__ == "__main__":
    # --- ×›××Ÿ ××ª× ×‘×•×—×¨×™× ××™×–×• ×ª××•× ×” ×œ×‘×“×•×§ ---
    # ×©×œ×‘ ×': ×ª×•×¨×™×“×• ×ª××•× ×” ××”××™× ×˜×¨× ×˜ ×•×ª×©××¨×• ××•×ª×” ×‘×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜
    # ×©×œ×‘ ×‘': ×©× ×• ××ª ×”×©× ×›××Ÿ ×œ×©× ×”×§×•×‘×¥ ×©×œ×›×
    image_to_test = "test_image.jpg" 
    
    # ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×§×™×™× ×œ×¤× ×™ ×©××¨×™×¦×™×
    if os.path.exists(image_to_test):
        predict(image_to_test)
    else:
        print(f"âŒ Please create/download an image named '{image_to_test}' in the project folder to test.")